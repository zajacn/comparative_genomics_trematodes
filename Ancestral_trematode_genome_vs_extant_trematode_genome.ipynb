{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trematodes analysis - reconstruction of ancestral Trematode and comparison of extant species to the ancestral genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pyham analysis. For pyham to work, we need some basic files that we can get from the omastandalone output: 1) the species tree and 2) the orthoxml file. The species tree gives the relationship between species, and the orthoxml gives all the information about the orthologs, in a hierarchical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all necessary scientific libraries\n",
    "import pandas as pd\n",
    "import pyham\n",
    "from collections import Counter\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "#  OPTIONAL: only if you want to have the logger information printed\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n",
    "\n",
    "# Read in a newick file as a taxonomy reference (species tree), here loaded the tree computed by omastandalone. Each ancestral node has to be labelled.\n",
    "# Read in a file of all hierarchical orthologous groups computed by omastandalone\n",
    "# Run ham anaylsis\n",
    "working_dir = 'your/working/directory'\n",
    "nwk_file = working_dir + \"EstimatedSpeciesTree.nwk\"\n",
    "orthoxml_file =  working_dir + \"HierarchicalGroups.orthoxml\"\n",
    "ham_analysis = pyham.Ham(nwk_file, orthoxml_file, use_internal_name=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the main pyham object, we can extract all the information from it. \n",
    "1. How many genes and which genes were duplicated, retained or gained from ancestral trematode in all extant trematodes. \n",
    "2. How many genes and which genes were duplicated, retained or gained from ancestral trematode in Atriophallophorus winterbourni. \n",
    "\n",
    "Pyham deals with ancestral genomes as well as extant genomes. It basically uses the extant genomes and orthology information to reconstruct the ancestral genomes. An ancestral genome can be considered as all the hogs present at a given taxonomic level. In the following analysis, the term \"trematode\" is used to refer to the ancestral trematode genome.\n",
    "\n",
    "In this strategy, we will perform a vertical comparison with the trematode ancestral genome to ALL the extant trematode species. Then for each of the species, we can see which genes were duplicated, retained, gained, or lost. Keep in mind that the lost genes don't carry much weight because we are assuming the genomes are fragmented and incomplete. \n",
    "\n",
    "We create a dataframe where each row is a gene and the columns will be: gene, species, class (duplicated, retained, etc), hog, hog family size, protein length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the protein fasta files and create a dataframe with all the genes per species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the protein fasta files\n",
    "\n",
    "genome_filenames = [\n",
    "\"Atriophallophorus_red3.agouti.run1.all.maker.proteins.fa\",\n",
    "\"Caenorhabditis_elegans.GCA_000002985.3_WBcel235_protein.fa\",\n",
    "\"Clonorchis_sinensis_GCA_003604175.1_ASM360417v1_protein.fa\",\n",
    "\"Ecchinococcus_granulosus_GCA_000524195.1_ASM52419v1_protein.fa\",\n",
    "\"Echinococcus_multilocularis_GCA_000469725.3_EMULTI002_protein.fa\",\n",
    "\"Echinostoma_caproni_GCA_900618425.1_Egypt_0011_upd_protein.fa\",\n",
    "\"Fasciola_hepatica_GCA_002763495.2_1.0.allpaths.pg_protein.fa\",\n",
    "\"Gyrodactylus_salaris_PRJNA244375.WBPS11_protein_fromwormbase.fa\",\n",
    "\"Opisthorchis_felineus_GCA_004794785.1_ICG_Ofel_1.0_protein.fa\",\n",
    "\"Opisthorchis_viverrini_GCA_001990785.1_1.0.pg.lrna_protein.fa\",\n",
    "\"Pristionchus_pacificus_GCA_000180635.3_El_Paco_protein.fa\",\n",
    "\"Schistosoma_bovis_GCA_003958945.1_ASM395894v1_protein.fa\",\n",
    "\"Schistosoma_curassoni_GCA_900618015.1_Dakar_0011_upd_protein.fa\",\n",
    "\"Schistosoma_haematobium_GCA_000699445.1_1.0_protein.fa\",\n",
    "\"Schistosoma_japonicum_GCA_006368765.1_ASM636876v1_protein.fa\",\n",
    "\"Schistosoma_mansoni_GCA_000237925.2_ASM23792v2_protein.fa\",\n",
    "\"Schistosoma_mattheei_GCA_900617995.1_Denwood_0011_upd_protein.fa\",\n",
    "\"Schistostoma_margrebowiei_GCA_900618395.1_Zambia_0011_upd_protein.fa\",\n",
    "\"Taenia_solium_PRJNA170813.WBPS11.protein_frompubwormbase.fa\",\n",
    "\"Trichobilharzia_regenti_GCA_900618515.1_v1_0_4_001_upd_protein.fa\"]\n",
    "\n",
    "# Create an empty dataframe to input all the data\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "# Read in all the genes from the fasta files\n",
    "for genome_filename in genome_filenames:\n",
    "    #read in fasta file\n",
    "    fasta_file = open(working_dir + \"DB/\"+ genome_filename)\n",
    "    #initiate a dictionary to store the lengths of all the genes\n",
    "    length_dict = {}\n",
    "\n",
    "    #read each sequence in the fasta file\n",
    "    for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        name = record.id\n",
    "        seq = record.seq\n",
    "        length_dict[name] = len(seq)\n",
    "    \n",
    "    #make a dataframe \n",
    "    df = pd.DataFrame.from_dict(length_dict, orient=\"index\").reset_index()\n",
    "    df.rename({\"index\":\"gene\", 0:\"protein_len\"}, inplace=True, axis=1)\n",
    "    \n",
    "    #add species\n",
    "    df['species'] = genome_filename.split(\".\")[0]\n",
    "    all_df = pd.concat([all_df, df])\n",
    "              \n",
    "\n",
    "# Define the trematodes in the analysis\n",
    "trematode_genome_filenames = [\n",
    "\"Atriophallophorus_red3.agouti.run1.all.maker.proteins.fa\",\n",
    "\"Clonorchis_sinensis_GCA_003604175.1_ASM360417v1_protein.fa\",\n",
    "\"Echinostoma_caproni_GCA_900618425.1_Egypt_0011_upd_protein.fa\",\n",
    "\"Fasciola_hepatica_GCA_002763495.2_1.0.allpaths.pg_protein.fa\",\n",
    "\"Opisthorchis_felineus_GCA_004794785.1_ICG_Ofel_1.0_protein.fa\",\n",
    "\"Opisthorchis_viverrini_GCA_001990785.1_1.0.pg.lrna_protein.fa\",\n",
    "\"Schistosoma_bovis_GCA_003958945.1_ASM395894v1_protein.fa\",\n",
    "\"Schistosoma_curassoni_GCA_900618015.1_Dakar_0011_upd_protein.fa\",\n",
    "\"Schistosoma_haematobium_GCA_000699445.1_1.0_protein.fa\",\n",
    "\"Schistosoma_japonicum_GCA_006368765.1_ASM636876v1_protein.fa\",\n",
    "\"Schistosoma_mansoni_GCA_000237925.2_ASM23792v2_protein.fa\",\n",
    "\"Schistosoma_mattheei_GCA_900617995.1_Denwood_0011_upd_protein.fa\",\n",
    "\"Schistostoma_margrebowiei_GCA_900618395.1_Zambia_0011_upd_protein.fa\",\n",
    "\"Trichobilharzia_regenti_GCA_900618515.1_v1_0_4_001_upd_protein.fa\"]\n",
    "\n",
    "\n",
    "trematode_genomes = [x.split(\".\")[0] for x in trematode_genome_filenames] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyHam allows tracing of HOGs/genes provided in the orthoxml file and through the protein files along each branch of a phylogenetic tree (provided in the newick format) and report the genes from these HOGs that arose through duplication on each branch, got lost on each branch, each appeared on that branch, or were simply retained. The vertical analysis allows for retrieval of all genes and their evolutionary history between the two taxonomic levels, the ancestral and  (i.e. which genes have been duplicated, which genes have been lost, etc).\n",
    "\n",
    "Define functions: 1. Classify each gene as duplicated, gained, retained and lost with respect to an ancestral genome and define how to run vertical analysis. 2. Convert duplicated, retained and gained genes obtained from comparison of extant to ancestral genome into lists. 3.From gene annotations of Fasciola hepatica, Schistosoma mansoni and Schistosoma japonicum (best studied species) obtain putative gene functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicated_gained_retained_lost_vertical(ham_analysis, genome1, genome2):\n",
    "    '''performs all vertical comparisons (getting dup, ret, lost, gained genes)\n",
    "    bettween two genomes (can be ancestral or extant)'''\n",
    "    genome1 = ham_analysis.get_ancestral_genome_by_name(genome1)\n",
    "    genome2 = ham_analysis.get_extant_genome_by_name(genome2)\n",
    "    \n",
    "    vertical_comparison = ham_analysis.compare_genomes_vertically(genome1, genome2)\n",
    "    \n",
    "    retained = vertical_comparison.get_retained()\n",
    "    duplicated = vertical_comparison.get_duplicated()\n",
    "    lost = vertical_comparison.get_lost()\n",
    "    gained = vertical_comparison.get_gained()\n",
    "    \n",
    "    return duplicated, gained, retained, lost\n",
    "\n",
    "\n",
    "def make_list_of_genes(dup_ret_gained):\n",
    "    '''This function just takes the pyham objects returned from the vertical analysis and converts them to lists'''\n",
    "    list_of_genes = []\n",
    "    \n",
    "    if isinstance(dup_ret_gained, dict):\n",
    "        for hog, gene in dup_ret_gained.items():\n",
    "            \n",
    "            #for duplicated\n",
    "            if isinstance(gene, list):\n",
    "                list_of_xrefs = [x.get_dict_xref()['protId'].split(\" \")[0] for x in gene]\n",
    "                list_of_genes.append(list_of_xrefs)\n",
    "\n",
    "            #for retained\n",
    "            else:\n",
    "                xref = gene.get_dict_xref()['protId'].split(\" \")[0]\n",
    "                list_of_genes.append(xref)\n",
    "    \n",
    "    #for gained\n",
    "    if isinstance(dup_ret_gained, list):\n",
    "        list_of_genes = [x.get_dict_xref()['protId'].split(\" \")[0] for x in dup_ret_gained]\n",
    "\n",
    "    return list_of_genes\n",
    "\n",
    "well_studied_species = [\"Fasciola_hepatica_GCA_002763495\", \\\n",
    "                        \"Schistosoma_mansoni_GCA_000237925\", \"Schistosoma_japonicum_GCA_006368765\"]\n",
    "\n",
    "def search_for_putative_function(hog, well_studied_species):\n",
    "    putative_functions = {}\n",
    "    hog = ham_analysis.get_hog_by_id(hog)\n",
    "    genes_in_hog = hog.get_all_descendant_genes_clustered_by_species()\n",
    "    for species, genes in genes_in_hog.items():\n",
    "        if species.name in well_studied_species:\n",
    "            for gene in genes:\n",
    "                xref = gene.get_dict_xref()\n",
    "                putative_functions[xref['protId'].split(\" \").pop(0)] = xref['protId'],'\\n'\n",
    "    return putative_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run vertical analysis in pyham between each extant trematode and the ancestral trematode genome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extant_genome in trematode_genomes:\n",
    "    duplicated, gained, retained, lost = get_duplicated_gained_retained_lost_vertical\\\n",
    "        (ham_analysis, \"Trematoda\", extant_genome)\n",
    "    \n",
    "    # Make lists of genes to facilitate transfer into df\n",
    "    retained_genes = make_list_of_genes(retained)\n",
    "    duplicated_genes = make_list_of_genes(duplicated)\n",
    "    duplicated_genes = [item for sublist in duplicated_genes for item in sublist]\n",
    "    gained_genes = make_list_of_genes(gained)\n",
    "    lost_genes = make_list_of_genes(lost)\n",
    "\n",
    "    # Classify all trematode genes as either duplicatetd, retained, or gained\n",
    "    all_df.loc[(all_df['gene'].isin(duplicated_genes)),'class'] = 'duplicated'\n",
    "    all_df.loc[(all_df['gene'].isin(retained_genes)),'class'] = 'retained'\n",
    "    all_df.loc[(all_df['gene'].isin(gained_genes)),'class'] = 'gained'\n",
    "    \n",
    "# Get rid of all other species that are not trematodes from the dataframe \n",
    "all_df.loc[(all_df['species'].isin(trematode_genomes)),'trematode'] = 'yes'\n",
    "all_df.loc[(all_df['species'].isnull()),'trematode'] = 'no'\n",
    "all_df[:5]\n",
    "trematode_df = all_df[all_df['trematode']==\"yes\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a root HOG (top level HOG) for each gene in the trematode_df table and establish the size of each othese HOGs including genes from all the trematode species. Add that to the table as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_hog_dict = {}\n",
    "\n",
    "for genome in trematode_df['species'].unique():\n",
    "    extant_genome = ham_analysis.get_extant_genome_by_name(genome)\n",
    "\n",
    "    for gene in extant_genome.genes:\n",
    "        xref = gene.get_dict_xref()['protId'].split(\" \")[0]\n",
    "        hog = gene.get_top_level_hog()\n",
    "        if hog.is_singleton():\n",
    "            gene_hog_dict[xref] = \"singleton\"\n",
    "        else:\n",
    "            gene_hog_dict[xref] = gene.get_top_level_hog().hog_id\n",
    "        \n",
    "trematode_df['hog'] = trematode_df['gene'].map(gene_hog_dict)\n",
    "\n",
    "# Number of genes in the whole hog (i.e. the gene family size or hog size, all the species together)\n",
    "\n",
    "hog_sizes = trematode_df.groupby('hog').size().reset_index()\n",
    "hog_sizes.rename({0:\"family_size\"}, inplace=True, axis=1)\n",
    "trematode_df = pd.merge(left=trematode_df, right=hog_sizes, how=\"left\", on=\"hog\")\n",
    "trematode_df.loc[(trematode_df['hog']==\"singleton\"),'family_size'] = 1\n",
    "\n",
    "# Add the number of genes per hog for each species and call it \"extant copy number\"\n",
    "\n",
    "copy_numbers = trematode_df.groupby(['species','hog']).size().reset_index()\n",
    "copy_numbers.rename({0:\"extant_copy_nr\"}, inplace=True, axis=1)\n",
    "trematode_df = pd.merge(left=trematode_df, right=copy_numbers, how=\"left\", on=[\"hog\",'species'])\n",
    "trematode_df.loc[(trematode_df['hog']==\"singleton\"),'extant_copy_nr'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genes that arose through duplication since trematode ancestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duplicated genes\n",
    "# Number of genes per HOG that got duplicated in each species since trematode ancestor has to be above or equal to copy_nb_threshold\n",
    "# Minimum number of species in which genes have to have duplicated in each family above the copy_nb_theshold is defined by species_nb_threshold\n",
    "\n",
    "copy_nb_threshold = 3\n",
    "trematode_df[(trematode_df['extant_copy_nr']>=copy_nb_threshold) &\\\n",
    "             (trematode_df['class']==\"duplicated\")].groupby('species').size()\n",
    "\n",
    "species_nb_threshold = 11\n",
    "# Sort the genes into top level HOG and give the HOG name and the number of species present\n",
    "\n",
    "df = trematode_df[(trematode_df['extant_copy_nr']>=copy_nb_threshold) &\\\n",
    "             (trematode_df['class']==\"duplicated\")].groupby(['hog','species']).\\\n",
    "size().reset_index(name='count').groupby(['hog']).size().reset_index(name=\"nb_species\")\n",
    "\n",
    "highly_duplicated_hogs_df = df[df[\"nb_species\"]>=species_nb_threshold]\n",
    "# Print the putative functions of genes in each HOG given the annotation of well studied species\n",
    "for hog in highly_duplicated_hogs_df['hog']:\n",
    "    print(\"HOG: \", hog)\n",
    "    functions = search_for_putative_function(hog, well_studied_species), \"\\n\"\n",
    "    print(functions, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highly duplicated genes *specifically* in Atriophallophorus winterbourni\n",
    "\n",
    "copy_nb_threshold = 3\n",
    "highly_duplicated_atrio_hogs_df = trematode_df[(trematode_df['species']==\"Atriophallophorus_red3\") \\\n",
    "             & (trematode_df['class']==\"duplicated\") \\\n",
    "             & (trematode_df['extant_copy_nr']>=copy_nb_threshold)].groupby(\"hog\").size().reset_index(name=\"nb_genes\")\n",
    "\n",
    "# Print the putative functions of Atriophallophorus winterbourni genes in each HOG given the annotation of well studied species\n",
    "for hog in highly_duplicated_atrio_hogs_df['hog']:\n",
    "    print(\"HOG: \", hog)\n",
    "    functions = hog, search_for_putative_function(hog, well_studied_species), \"\\n\"\n",
    "    print(functions, \"\\n\")\n",
    "# Print number of genes of A.winterbourni in each HOG\n",
    "print(len(highly_duplicated_atrio_hogs_df['hog']))    \n",
    "\n",
    "# Make a list of those genes that arose through duplication in A.winterbourni in each HOG and output them to a file.\n",
    "highly_duplicated_atrio_genes_df  = trematode_df[(trematode_df['class']==\"duplicated\") \\\n",
    "                      & (trematode_df['species']==\"Atriophallophorus_red3\") \\\n",
    "                         & (trematode_df['extant_copy_nr']>copy_nb_threshold)]['gene'].tolist()\n",
    "with open(working_dir + 'highly_duplicated_atrio_genes.txt', 'w') as filehandle:\n",
    "    for gene in mygenes_df:\n",
    "        filehandle.write('%s\\n' % gene)\n",
    "        \n",
    "# Get protein sequences for all these genes from a concatenated fasta file containing all species proteins all_sequences.fa\n",
    "for gene in highly_duplicated_atrio_genes_df:\n",
    "           record_dict = SeqIO.to_dict(SeqIO.parse(working_dir + \"DB/\" + \"all_sequences.fa\", \"fasta\"))\n",
    "           print(record_dict[gene].seq)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highly duplicated for each species just as previously only for A.winterbourni, so it does not have to be shared duplications\n",
    "# Duplications must have happened anytime after trematode speciation\n",
    "# copy_nb_threshold - number of duplications since trematode ancestor\n",
    "\n",
    "copy_nb_threshold = 3\n",
    "print(\"AT LEAST \" + str(copy_nb_threshold) + \" COPIES IN GENOME\" + \"\\n--------------------------\\n\")\n",
    "\n",
    "for genome in trematode_genomes:\n",
    "    print(genome + \"\\n**********************\")\n",
    "    highly_duplicated_hogs_df = trematode_df[(trematode_df['species']==genome) \\\n",
    "                 & (trematode_df['class']==\"duplicated\") \\\n",
    "                 & (trematode_df['extant_copy_nr']>copy_nb_threshold)].groupby(\"hog\").size().reset_index(name=\"nb_genes\")\n",
    "\n",
    "# Print the putative functions of the genes in each HOG given the annotation of well studied species\n",
    "    for hog in highly_duplicated_hogs_df['hog']:\n",
    "        print(\"HOG: \", hog)\n",
    "        functions = hog, search_for_putative_function(hog, well_studied_species), \"\\n\"\n",
    "        print(functions, \"\\n\")\n",
    "\n",
    "# Get protein sequences for all these genes from a concatenated fasta file containing all species proteins all_sequences.fa\n",
    "    for gene in highly_duplicated_hogs_df:\n",
    "           record_dict = SeqIO.to_dict(SeqIO.parse(working_dir + \"DB/\" + \"all_sequences.fa\", \"fasta\"))\n",
    "           print(record_dict[gene].seq)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retained genes since trematode ancestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the retained genes in extant species since the trematode ancestor\n",
    "# Nb_species_threshold defines how many species minimum the retained genes have to be present in\n",
    "# Family_size_threshold is the size of the HOG and because we are looking for 1:1 orthologs the family size has to be equal to the number of species present in that family\n",
    "\n",
    "nb_species_threshold = 14\n",
    "family_size_threshold = nb_species_threshold\n",
    "\n",
    "df = trematode_df[(trematode_df['class']==\"retained\") & (trematode_df['family_size']<=family_size_threshold)].\\\n",
    "    groupby(['hog','species']).size().reset_index(name='count')\\\n",
    "    .groupby(['hog']).size().reset_index(name=\"nb_species\")\n",
    "\n",
    "highly_conserved_hogs_df = df[df[\"nb_species\"]>= nb_species_threshold]\n",
    "\n",
    "# Print the putative functions of the genes in each HOG given the annotation of well studied species\n",
    "for hog in highly_conserved_hogs_df['hog']:\n",
    "    print(\"HOG: \", hog)\n",
    "    functions = hog, search_for_putative_function(hog, well_studied_species), \"\\n\"\n",
    "    print(functions, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Ontology Enrichment Analysis for gained, retained and duplicated genes in each extant species since the ancestral trematode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform this analysis one needs to obtain all genes from each category per species, not shared genes between all trematodes. One also needs annotation of all genomes used with Pannzer2 (http://ekhidna2.biocenter.helsinki.fi/sanspanz/), OMA (https://omabrowser.org/oma/functions/) and EggNOG (http://eggnog5.embl.de/#/app/home). One also needs to download a gene ontology file describing relationships between GO terms (http://geneontology.org/docs/download-ontology/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define all necessary functions\n",
    "import pandas as pd\n",
    "from goatools import obo_parser\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "import matplotlib.pyplot as plt\n",
    "import pyham\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ontologies\n",
    "#read in downloaded go ontology file (describes terms and relationships among them)\n",
    "go = obo_parser.GODag(working_dir + 'go.obo')\n",
    "\n",
    "#You must follow the code above to recontstruct ancestral trematode and create a trematode_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First make a dataframe for all go terms for all extant genes in whole analysis.\n",
    "def read_in_pannzera_go_annotations(go_annotations_infile, species):\n",
    "    '''returns a formatted pandas dataframe with relevant go info'''\n",
    "    df = pd.read_csv(go_annotations_infile, sep=\"\\t\", dtype={'goid': object})\n",
    "    df = df.rename({\"qpid\":\"gene\", \"goid\":\"GO_term\"}, axis=1)\n",
    "    df['GO_term'] = df['GO_term'].apply(lambda x: \"GO:\"+ x)\n",
    "    df['source'] = \"PANNZER\"\n",
    "    df['species'] = species\n",
    "    df['gene_go_term_combo'] = df['gene'] + \"_\" + df['GO_term']\n",
    "    df = df.dropna(axis=0).drop_duplicates()\n",
    "    #print(\"Read in {} GO annotations for {}.\".format(len(df), go_annotations_infile))\n",
    "    df = df[['species','gene', 'GO_term', 'source','gene_go_term_combo']]\n",
    "    return df\n",
    "\n",
    "def read_in_oma_go_annotations(go_annotations_infile, species):\n",
    "    df = pd.read_csv(go_annotations_infile, sep=\"\\t\", skiprows=4, header=None)\n",
    "    df = df[[1,4]].rename({1:\"gene\", 4:\"GO_term\"}, axis=1)\n",
    "    df['source'] = \"OMA\"\n",
    "    df['species'] = species\n",
    "    df['gene_go_term_combo'] = df['gene'] + \"_\" + df['GO_term']\n",
    "    df = df.dropna(axis=0).drop_duplicates()\n",
    "    #print(\"Read in {} GO annotations for {}.\".format(len(df), go_annotations_infile))\n",
    "    df = df[['species','gene', 'GO_term', 'source','gene_go_term_combo']]\n",
    "    return df\n",
    "\n",
    "def read_in_eggnog_go_annotations(go_annotations_infile, species):\n",
    "    df = pd.read_csv(go_annotations_infile, sep=\"\\t\", header=None)\n",
    "    df = df[[1,2]].rename({1:\"gene\", 2:\"GO_term\"}, axis=1)\n",
    "    df['source'] = \"EGGNOG\"\n",
    "    df['species'] = species\n",
    "    df['gene_go_term_combo'] = df['gene'] + \"_\" + df['GO_term']\n",
    "    df = df.dropna(axis=0).drop_duplicates()\n",
    "    #print(\"Read in {} GO annotations for {}.\".format(len(df), go_annotations_infile))\n",
    "    df = df[['species','gene', 'GO_term', 'source','gene_go_term_combo']]\n",
    "    return df\n",
    "\n",
    "pannzera_go_annotations = [\"PAN_GO_Atriophallophorus_red3.txt\",\n",
    "\"PAN_GO_Clonorchis_sinensis_GCA_003604175.txt\",\n",
    "\"PAN_GO_Ecchinococcus_granulosus_GCA_000524195.txt\",\n",
    "\"PAN_GO_Echinococcus_multilocularis_GCA_000469725.txt\",\n",
    "\"PAN_GO_Echinostoma_caproni_GCA_900618425.txt\",\n",
    "\"PAN_GO_Fasciola_hepatica_GCA_002763495.txt\",\n",
    "\"PAN_GO_Opisthorchis_felineus_GCA_004794785.txt\",\n",
    "\"PAN_GO_Opisthorchis_viverrini_GCA_001990785.txt\",\n",
    "\"PAN_GO_Schistosoma_bovis_GCA_003958945.txt\",\n",
    "\"PAN_GO_Schistosoma_curassoni_GCA_900618015.txt\",\n",
    "\"PAN_GO_Schistosoma_japonicum_GCA_006368765.txt\",\n",
    "\"PAN_GO_Schistosoma_mansoni_GCA_000237925.txt\",\n",
    "\"PAN_GO_Schistosoma_mattheei_GCA_900617995.txt\",\n",
    "\"PAN_GO_Schistosoma_haematobium_GCA_000699445.txt\",\n",
    "\"PAN_GO_Schistostoma_margrebowiei_GCA_900618395.txt\",\n",
    "\"PAN_GO_Trichobilharzia_regenti_GCA_900618515.txt\"]\n",
    "\n",
    "oma_go_annotations = [\"OMA_GO_Atriophallophorus_red3.txt\",\n",
    "\"OMA_GO_Clonorchis_sinensis_GCA_003604175.txt\",\n",
    "\"OMA_GO_Echinostoma_caproni_GCA_900618425.txt\",\n",
    "\"OMA_GO_Fasciola_hepatica_GCA_002763495.txt\",\n",
    "\"OMA_GO_Opisthorchis_viverrini_GCA_001990785.txt\",\n",
    "\"OMA_GO_Opisthorchis_felineus_GCA_004794785.txt\",\n",
    "\"OMA_GO_Schistosoma_bovis_GCA_003958945.txt\",\n",
    "\"OMA_GO_Schistosoma_curassoni_GCA_900618015.txt\",\n",
    "\"OMA_GO_Schistosoma_haematobium_GCA_000699445.txt\",\n",
    "\"OMA_GO_Schistosoma_japonicum_GCA_006368765.txt\",\n",
    "\"OMA_GO_Schistosoma_mansoni_GCA_000237925.txt\",\n",
    "\"OMA_GO_Schistosoma_mattheei_GCA_900617995.txt\",\n",
    "\"OMA_GO_Schistostoma_margrebowiei_GCA_900618395.txt\",\n",
    "\"OMA_GO_Trichobilharzia_regenti_GCA_900618515.txt\"]\n",
    "\n",
    "eggnog_go_annotations = [\"EGGNOG_Atriophallophorus_red3.txt\",\n",
    "\"EGGNOG_Clonorchis_sinensis_GCA_003604175.txt\",\n",
    "\"EGGNOG_Echinostoma_caproni_GCA_900618425.txt\",\n",
    "\"EGGNOG_Fasciola_hepatica_GCA_002763495.txt\",\n",
    "\"EGGNOG_Opisthorchis_felineus_GCA_004794785.txt\",\n",
    "\"EGGNOG_Opisthorchis_viverrini_GCA_001990785.txt\",\n",
    "\"EGGNOG_Schistosoma_bovis_GCA_003958945.txt\",\n",
    "\"EGGNOG_Schistosoma_curassoni_GCA_900618015.txt\",\n",
    "\"EGGNOG_Schistosoma_japonicum_GCA_006368765.txt\",\n",
    "\"EGGNOG_Schistosoma_haematobium_GCA_000699445.txt\",\n",
    "\"EGGNOG_Schistosoma_mansoni_GCA_000237925.txt\",\n",
    "\"EGGNOG_Schistosoma_mattheei_GCA_900617995.txt\",\n",
    "\"EGGNOG_Schistostoma_margrebowiei_GCA_900618395.txt\",\n",
    "\"EGGNOG_Trichobilharzia_regenti_GCA_900618515.txt\"]\n",
    "#read in all data\n",
    "all_go_df = pd.DataFrame(columns = ['gene', 'GO_term', 'source', 'species', 'gene_go_term_combo'])\n",
    "\n",
    "for file in pannzera_go_annotations:\n",
    "    species = file.split(\".\")[0].split(\"PAN_GO_\")[1]\n",
    "    df = read_in_pannzera_go_annotations(working_dir + \"/DB/\" + file, species)\n",
    "    all_go_df = all_go_df.append(df)\n",
    "    \n",
    "for file in oma_go_annotations:\n",
    "    species = file.split(\".\")[0].split(\"OMA_GO_\")[1]\n",
    "    df = read_in_oma_go_annotations(working_dir + \"/DB/\" + file, species)\n",
    "    all_go_df = all_go_df.append(df)\n",
    "    \n",
    "for file in eggnog_go_annotations:\n",
    "    species = file.split(\".\")[0].split(\"EGGNOG_\")[1]\n",
    "    df = read_in_eggnog_go_annotations(working_dir + \"/DB/\" + file, species)\n",
    "    all_go_df = all_go_df.append(df)    \n",
    "\n",
    "print(len(all_go_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for the whole analysis\n",
    "species_list= [\n",
    "\"Atriophallophorus_red3\",\n",
    "\"Clonorchis_sinensis_GCA_003604175\",\n",
    "\"Echinostoma_caproni_GCA_900618425\",\n",
    "\"Fasciola_hepatica_GCA_002763495\",\n",
    "\"Opisthorchis_felineus_GCA_004794785\",\n",
    "\"Opisthorchis_viverrini_GCA_001990785\",\n",
    "\"Schistosoma_bovis_GCA_003958945\",\n",
    "\"Schistosoma_curassoni_GCA_900618015\",\n",
    "\"Schistosoma_haematobium_GCA_000699445\",\n",
    "\"Schistosoma_japonicum_GCA_006368765\",\n",
    "\"Schistosoma_mattheei_GCA_900617995\",\n",
    "\"Schistostoma_margrebowiei_GCA_900618395\",\n",
    "\"Trichobilharzia_regenti_GCA_900618515\"]\n",
    "\n",
    "def get_go_associations(choose_source, all_go_df, species):\n",
    "    '''This function creates the association dictionary, based on if you want the\n",
    "    intersection, union, one or the other of GO annotations'''\n",
    "    #initiate an empty dictionary\n",
    "    associations = {}\n",
    "\n",
    "    if choose_source == \"pannzer\":\n",
    "        df = all_go_df[(all_go_df['source']== \"PANNZER\") & (all_go_df['species']== species)]\n",
    "        \n",
    "    if choose_source == \"oma\":\n",
    "        df = all_go_df[(all_go_df['source']== \"OMA\") & (all_go_df['species']== species)]\n",
    "        \n",
    "    if choose_source == \"eggnog\":\n",
    "        df = all_go_df[(all_go_df['source']== \"EGGNOG\") & (all_go_df['species']== species)]\n",
    "    \n",
    "        #make a pandas grouped by object to get all the go terms for each gene\n",
    "    grouped_obj = df.groupby('gene')\n",
    "        \n",
    "        #iterate through genes in grouped object\n",
    "    for gene in grouped_obj.groups.keys():\n",
    "    \n",
    "            #create a list of GO terms for each gene\n",
    "            all_go_terms = grouped_obj.get_group(gene)['GO_term'].tolist()\n",
    "\n",
    "\n",
    "            #add it to the dictionary\n",
    "            associations[gene] = set(all_go_terms)\n",
    "        \n",
    "    return associations\n",
    "\n",
    "for species in species_list:\n",
    "    print(\"Number of genes with GO terms:\", species)\n",
    "    print(\"pannzer\", len(get_go_associations(\"pannzer\", all_go_df, species)))\n",
    "    print(\"oma\", len(get_go_associations(\"oma\", all_go_df, species)))\n",
    "    print(\"eggnog\", len(get_go_associations(\"eggnog\", all_go_df, species)))\n",
    "\n",
    "def get_population_set(df, species):\n",
    "    '''Get all the genes in the whole population. This is the background for the GO enrichment.'''\n",
    "    population = set(df[(df['species']==species)]['gene'].tolist())\n",
    "    print(\"There are {} genes in the study population.\".format(len(population)))\n",
    "    return population\n",
    "\n",
    "def get_study_genes(species, df, gene_class, copy_nb_threshold=1, hog=None):\n",
    "    '''Returns a dataframe with the specified genes, can add an optional speciific hog'''\n",
    "    study_genes_df = df[(df['species']==species) & (df['class']==gene_class) & (df['extant_copy_nr']>=copy_nb_threshold)]\n",
    "    \n",
    "    if hog!= None:\n",
    "        study_genes_df = study_genes_df[study_genes_df['hog']==hog]\n",
    "        \n",
    "    return study_genes_df\n",
    "\n",
    "def make_go_study_obj(population, associations, go, propagate_counts=True):\n",
    "    '''Use goatools to make GO enrichment study object. \n",
    "    population == background gene set\n",
    "    associations == dictionary of gene: {go terms}\n",
    "    go == go obo file\n",
    "    '''\n",
    "    methods = ['bonferroni', 'sidak', 'holm']\n",
    "    go_study_obj = GOEnrichmentStudy(population, associations, go, \n",
    "                              propagate_counts=propagate_counts, \n",
    "                              alpha=0.05, \n",
    "                              methods=methods)\n",
    "    return go_study_obj\n",
    "\n",
    "def run_and_save_goenr(go_study_obj, list_of_genes_for_enrichment, working_dir):\n",
    "    '''Do the go enrichment and write to file'''\n",
    "    res = go_study_obj.run_study(list_of_genes_for_enrichment)\n",
    "    go_study_obj.wr_tsv(working_dir + 'GO_df.tsv', res)\n",
    "    return res\n",
    "\n",
    "def read_in_goenr_tsv(enriched_or_depleted, p_cutoff, path_to_tsv):\n",
    "    '''Read in go enrichment file into a dataframe, choosing if you want to filter for enriched or depleted results'''\n",
    "    if enriched_or_depleted in [\"depleted\",\"p\"]:\n",
    "        e_or_p = \"p\"\n",
    "        print(\"depleted\")\n",
    "    else:\n",
    "        e_or_p = \"e\"\n",
    "        print(\"enriched\")\n",
    "    df = pd.read_csv(path_to_tsv, sep=\"\\t\")\n",
    "    df = df[(df['enrichment']==e_or_p) & (df['p_bonferroni'] <= p_cutoff)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_for_revigo(go_df, depth_cutoff=0):\n",
    "    '''simply print the enriched GO terms and their p-values in order to copy and paste into revigo'''\n",
    "    print(go_df[go_df['depth']>=depth_cutoff][[\"# GO\",\"p_bonferroni\"]].to_string(index=False, justify=\"left\"))\n",
    "    \n",
    "def get_fold_change(go_df):\n",
    "    #convert ratios to floats and calculate fold change\n",
    "    go_df['ratio_in_study2'] = go_df['ratio_in_study'].apply(lambda x: float(sum(Fraction(s) for s in x.split())))\n",
    "    go_df['ratio_in_pop2'] = go_df['ratio_in_pop'].apply(lambda x: float(sum(Fraction(s) for s in x.split())))\n",
    "\n",
    "    go_df['fold_change'] = go_df.apply(lambda x: x['ratio_in_study2']/x['ratio_in_pop2'], axis=1)\n",
    "    return go_df\n",
    "\n",
    "def run_go_pipeline_for_genes_part2(study_genes, go_study_obj):\n",
    "    #second part of GO enrichment (can change the study gene sets)\n",
    "    #5. run gene ontology enrichment analysis\n",
    "    run_and_save_goenr(go_study_obj, study_genes, working_dir)\n",
    "\n",
    "    #6. read in dataframe that was just saved\n",
    "    go_df = pd.read_csv(working_dir+\"GO_df.tsv\", sep=\"\\t\")\n",
    "\n",
    "    #7. Filter by p-value and only looking at enriched not depleted go terms!\n",
    "    go_df = go_df[(go_df['p_bonferroni']<=.05) & (go_df['enrichment']==\"e\")] \n",
    "    \n",
    "    if len(go_df)>0:\n",
    "        go_df = get_fold_change(go_df)\n",
    "        \n",
    "    return go_df\n",
    "\n",
    "#Define a function to complete an output GO enrichment table\n",
    "def make_final_go_df(df, species):\n",
    "    df = df\n",
    "    df['species'] = species\n",
    "    df['class'] = \"duplicated\"\n",
    "    df = df[['# GO','NS','depth','name','enrichment', 'fold_change', 'p_uncorrected','p_bonferroni', 'p_holm', 'p_sidak', 'ratio_in_pop', 'ratio_in_pop2','ratio_in_study', 'ratio_in_study2', 'study_count','study_items', 'species', 'class']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally run the analysis\n",
    "output = pd.DataFrame()\n",
    "\n",
    "#Change \"duplicated\" into either \"gained\" or \"retained\"\n",
    "for species in species_list:\n",
    "    population = get_population_set(trematode_df, species)\n",
    "    associations = get_go_associations(\"pannzer\", all_go_df, species)\n",
    "    my_study_genes = trematode_df[(trematode_df['species']== species) & (trematode_df['class']==\"duplicated\")]['gene'].tolist()\n",
    "    go_study_obj = make_go_study_obj(population, associations, go)\n",
    "    run_and_save_goenr(go_study_obj, my_study_genes, working_dir)\n",
    "    go_df = pd.read_csv(working_dir+\"GO_df.tsv\", sep=\"\\t\")\n",
    "    go_df = run_go_pipeline_for_genes_part2(my_study_genes, go_study_obj)\n",
    "    df_final = make_final_go_df(go_df, species)\n",
    "    if not df_final.empty:\n",
    "        output = pd.concat([output, df_final])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have completed the analysis you might want to concatenate all the data into one dataframe and visualise it. In order to do that one can categorise all the GO terms in GO slim categories (http://geneontology.org/docs/download-ontology/). In our analysis we used the AGR subset. One can also calculate the average information content per GO slim category. For our analysis the IC (Information Content) score was calculated as: IC(t)=âˆ’log(p(t)) with p(t) being estimated as the empirical frequency of the term in UniProt-GOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the table created in previous analysis and add the IC values to each GO term\n",
    "final_go_df = pd.read_csv(working_dir + 'proteinlength/' + 'GO_forallgenes_forallspecies.txt', sep=\"\\t\")\n",
    "\n",
    "ic_df = pd.read_csv(working_dir + 'ic.tsv.gz', sep='\\t')\n",
    "ic_df['GO'] = ic_df['t'].apply(lambda x: \"GO:\"+ str(x).rjust(7,'0')) #this pads the GO so its in the right format\n",
    "\n",
    "#add the positive IC to the final_go_df\n",
    "final_go_df = pd.merge(left=final_go_df, right=ic_df[['GO','pos_ic']], how=\"left\", on=\"GO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary functions and AGR GO slim terms\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "slim_AGR = [\"GO:0000003\",\n",
    "\"GO:0002376\",\n",
    "\"GO:0003677\",\n",
    "\"GO:0003700\",\n",
    "\"GO:0003723\",\n",
    "\"GO:0003824\",\n",
    "\"GO:0005102\",\n",
    "\"GO:0005198\",\n",
    "\"GO:0005215\",\n",
    "\"GO:0005576\",\n",
    "\"GO:0005634\",\n",
    "\"GO:0005694\",\n",
    "\"GO:0005739\",\n",
    "\"GO:0005768\",\n",
    "\"GO:0005773\",\n",
    "\"GO:0005783\",\n",
    "\"GO:0005794\",\n",
    "\"GO:0005829\",\n",
    "\"GO:0005856\",\n",
    "\"GO:0005886\",\n",
    "\"GO:0005975\",\n",
    "\"GO:0006259\",\n",
    "\"GO:0006629\",\n",
    "\"GO:0007049\",\n",
    "\"GO:0007610\",\n",
    "\"GO:0008092\",\n",
    "\"GO:0008134\",\n",
    "\"GO:0008219\",\n",
    "\"GO:0008283\",\n",
    "\"GO:0008289\",\n",
    "\"GO:0009056\",\n",
    "\"GO:0016043\",\n",
    "\"GO:0016070\",\n",
    "\"GO:0019538\",\n",
    "\"GO:0023052\",\n",
    "\"GO:0030054\",\n",
    "\"GO:0030154\",\n",
    "\"GO:0030234\",\n",
    "\"GO:0030246\",\n",
    "\"GO:0031410\",\n",
    "\"GO:0032502\",\n",
    "\"GO:0032991\",\n",
    "\"GO:0036094\",\n",
    "\"GO:0038023\",\n",
    "\"GO:0042592\",\n",
    "\"GO:0042995\",\n",
    "\"GO:0045202\",\n",
    "\"GO:0046872\",\n",
    "\"GO:0050877\",\n",
    "\"GO:0050896\",\n",
    "\"GO:0051234\",\n",
    "\"GO:0097367\",\n",
    "\"GO:1901135\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the terms from the df that I want to map to their GO slim term\n",
    "go_terms_to_slim = list(set(final_go_df['GO'].tolist()))\n",
    "len(go_terms_to_slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the EBI website to map go terms to their slim term\n",
    "\n",
    "def format_go_terms_for_url(list_of_go_terms):\n",
    "    '''Prepares a list of go terms for url by concatenting them in the special format'''\n",
    "    go_ids_just_numbers = [\"GO%3A\" + x.split(\":\")[1] + '%2C' for x in list_of_go_terms]\n",
    "    go_ids_for_url = ''.join(go_ids_just_numbers) \n",
    "    return(go_ids_for_url)\n",
    "\n",
    "def get_slim_df(slim_set, go_terms_to_slim):\n",
    "    '''makes the url and request to map the go terms to their go slim term. \n",
    "    Stores result in a df'''\n",
    "    \n",
    "    slim_url = \"https://www.ebi.ac.uk/QuickGO/services/ontology/go/slim?slimsToIds=\" + format_go_terms_for_url(slim_set)\n",
    "    \n",
    "    go_ids_url = format_go_terms_for_url(go_terms_to_slim)\n",
    "\n",
    "    requestURL = slim_url + \"&slimsFromIds=\" + go_ids_url + \"&relations=is_a%2Cpart_of%2Coccurs_in%2Cregulates\"\n",
    "\n",
    "    r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "      sys.exit()\n",
    "\n",
    "    slim_df = pd.DataFrame(r.json()['results'])\n",
    "    slim_df['slimsToIds'] = slim_df['slimsToIds'].apply(lambda x: x[0])\n",
    "\n",
    "    return slim_df\n",
    "\n",
    "#split terms to map to go slim into chunks\n",
    "chunked_go_terms_to_slim = np.array_split(go_terms_to_slim, 10)\n",
    "\n",
    "slim_df = pd.DataFrame()\n",
    "\n",
    "#run the requests by chunks\n",
    "for chunk in chunked_go_terms_to_slim:\n",
    "    tmp_df = get_slim_df(slim_AGR, chunk)\n",
    "    slim_df = slim_df.append(tmp_df)\n",
    "    \n",
    "slim_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But we don't know the names of the GO slim terms, so we can also get that from the EBI API:\n",
    "def get_slim_names(go_ids_to_get_names_for):\n",
    "    '''This function just gets the name of a given GO term'''\n",
    "    \n",
    "    requestURL_names = \"https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/\" + format_go_terms_for_url(go_ids_to_get_names_for)\n",
    "\n",
    "    r = requests.get(requestURL_names, headers={ \"Accept\" : \"application/json\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "      sys.exit()\n",
    "\n",
    "    responses = r.json()['results']\n",
    "    names_df = pd.DataFrame(responses)\n",
    "    names_df = names_df[['id','name']]\n",
    "    names_df = names_df.rename({'name':\"go_slim_name\"}, axis=1)\n",
    "    \n",
    "    return names_df\n",
    "\n",
    "\n",
    "#split into chunks so server will run\n",
    "chunked_go_terms = np.array_split(slim_df['slimsToIds'], 10)\n",
    "\n",
    "names_df = pd.DataFrame()\n",
    "\n",
    "for chunk in chunked_go_terms:\n",
    "    tmp_df = get_slim_names(chunk)\n",
    "    names_df = names_df.append(tmp_df)\n",
    "    \n",
    "names_df = names_df.drop_duplicates()\n",
    "    \n",
    "names_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the final GO table\n",
    "final_go_df = pd.merge(left=final_go_df, right=slim_df, how=\"left\", left_on=\"GO\", right_on=\"slimsFromId\")\n",
    "final_go_df = pd.merge(left=final_go_df, right=names_df, left_on=\"slimsToIds\", right_on=\"id\")\n",
    "\n",
    "final_go_df = final_go_df[[ 'species','gene class','GO','name','id','go_slim_name','NS', 'depth', 'enrichment',\n",
    "         'p_uncorrected','p_bonferroni', 'p_holm', 'p_sidak','ratio_in_pop', 'ratio_in_pop2',\n",
    "       'ratio_in_study', 'ratio_in_study2',  'fold_change', 'study_count','study_items', 'pos_ic']]\n",
    "final_go_df = final_go_df.rename({\"id\":\"GO_slim\"}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_study_genes(study_items_string_list, species_of_interest):   \n",
    "    '''This function takes a series of study genes (strings) from the GO enrichment and separates them all in a list'''\n",
    "    \n",
    "    \n",
    "    #initiate empty list where will will store the final list of genes\n",
    "    mygenes = []\n",
    "\n",
    "    #input data\n",
    "    #print(\"This is what the original data looks like: \")\n",
    "\n",
    "    #go through all the cells of study items, if there are multiple rows (i.e. multiple go terms for a given go slim)\n",
    "    for study_items in study_items_string_list:\n",
    "        #how many genes?\n",
    "        #print(\"nb genes: \", len(study_items))\n",
    "\n",
    "        #what is the datatype? (i.e. string vs. list)\n",
    "        #print(type(study_items))\n",
    "        #print(\"study_items: \", study_items, \"\\n\")\n",
    "\n",
    "        #split each element (study_item) into individual genes\n",
    "        separate_genes = study_items.split(\",\")\n",
    "        #print(\"separate_genes: \", separate_genes,\"\\n\")\n",
    "\n",
    "        #This part removes the square brackets from ancestral genes, as well as whitespace (strip)\n",
    "        separate_genes = [x.replace(\"[\", \"\") for x in separate_genes]\n",
    "        separate_genes = [x.replace(\"]\", \"\") for x in separate_genes]\n",
    "        separate_genes = [x.strip() for x in separate_genes]\n",
    "\n",
    "        #print(\"separate_genes, with whitespace and brackets removed: \", separate_genes, \"\\n\")\n",
    "        #print(\"separate_genes is now a {}.\\n\".format(type(separate_genes)))\n",
    "\n",
    "        #add our list of genes to mygenes\n",
    "        mygenes.append(separate_genes)\n",
    "\n",
    "    #print(\"---------------ALL LOOPS DONE---------------\\n\")\n",
    "\n",
    "    #what does mygenes look like?\n",
    "    #print(\"mygenes: \", mygenes, \"\\n\")\n",
    "\n",
    "    #we can see that mygenes is a list of lists, so we need to flatten the list\n",
    "    mygenes = [item for sublist in mygenes for item in sublist]\n",
    "\n",
    "    #now we can see it is one big list, not several lists anymore\n",
    "    #print(\"mygenes, only 1 list:\", mygenes, \"\\n\")\n",
    "\n",
    "    #now we have to remove duplicates from the list\n",
    "    mygenes = set(mygenes)\n",
    "    #print(\"final mygenes: \", mygenes, \"\\n\")\n",
    "\n",
    "    return mygenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_slim_names = set(final_go_df['go_slim_name'].tolist())\n",
    "\n",
    "\n",
    "#initiate and emtpy data frame to store the final counts\n",
    "go_slim_names_gene_counts_df = pd.DataFrame()\n",
    "\n",
    "#loop through all of species, gene classes, and go slim names\n",
    "for specie_of_interest in species_of_interest:\n",
    "    for gene_class in gene_classes:\n",
    "        for go_slim_name in go_slim_names:\n",
    "            \n",
    "            #select the data we want, which are the rows that correspond to our ancestor, gene class, and go slim\n",
    "            subset_df = final_go_df[(final_go_df['species']== specie_of_interest) &\\\n",
    "                                    (final_go_df['gene class']== gene_class) &\\\n",
    "                                       (final_go_df['go_slim_name']==go_slim_name)]\n",
    "            \n",
    "            #we only want study items (i.e. enriched genes)\n",
    "            study_items = subset_df['study_items']\n",
    "            \n",
    "            #get the mean positive information content\n",
    "            mean_pos_ic = subset_df['pos_ic'].mean()\n",
    "            \n",
    "            #use the function from the code block above to split the study genes\n",
    "            mygenes = split_study_genes(study_items, specie_of_interest)\n",
    "            \n",
    "            #how many are there?\n",
    "            count = len(mygenes)\n",
    "            \n",
    "            #make a row containing all of this information...\n",
    "            tmp_df = pd.DataFrame({\"species\": [specie_of_interest], \"gene class\": [gene_class],\\\n",
    "                                   \"go_slim_name\": [go_slim_name], \"nb_genes\": count, \"mean_IC\": mean_pos_ic})\n",
    "            \n",
    "            #and add it to the \n",
    "            go_slim_names_gene_counts_df = go_slim_names_gene_counts_df.append(tmp_df)\n",
    "            \n",
    "\n",
    "#There will be some blanks in the dataframe because not every ancestor or gene class has enriched genes in every GO slim category. So we fill those with 0.\n",
    "go_slim_names_gene_counts_df = go_slim_names_gene_counts_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output\n",
    "final_go_df.to_csv(working_dir + \"proteinlength/\" + \"final_go_df.txt\", sep=\"\\t\")\n",
    "go_slim_names_gene_counts_df.to_csv(working_dir + \"proteinlength/\" + \"go_slim_names_gene_counts_df.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "for gene_class in gene_classes:\n",
    "    annotations = go_slim_names_gene_counts_df[go_slim_names_gene_counts_df['gene class']==gene_class]\\\n",
    "                .pivot(\"species\",\"go_slim_name\",\"nb_genes\").T[[\n",
    "\"Atriophallophorus_red3\",\n",
    "\"Clonorchis_sinensis_GCA_003604175\",\n",
    "\"Echinostoma_caproni_GCA_900618425\",\n",
    "\"Fasciola_hepatica_GCA_002763495\",\n",
    "\"Opisthorchis_felineus_GCA_004794785\",\n",
    "\"Opisthorchis_viverrini_GCA_001990785\",\n",
    "\"Schistosoma_bovis_GCA_003958945\",\n",
    "\"Schistosoma_curassoni_GCA_900618015\",\n",
    "\"Schistosoma_haematobium_GCA_000699445\",\n",
    "\"Schistosoma_japonicum_GCA_006368765\",\n",
    "\"Schistosoma_mattheei_GCA_900617995\",\n",
    "\"Schistostoma_margrebowiei_GCA_900618395\",\n",
    "\"Trichobilharzia_regenti_GCA_900618515\"]]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "    sns.heatmap(go_slim_names_gene_counts_df[go_slim_names_gene_counts_df['gene class']==gene_class]\\\n",
    "                .pivot(\"species\",\"go_slim_name\",\"mean_IC\").T[[\n",
    "\"Atriophallophorus_red3\",\n",
    "\"Clonorchis_sinensis_GCA_003604175\",\n",
    "\"Echinostoma_caproni_GCA_900618425\",\n",
    "\"Fasciola_hepatica_GCA_002763495\",\n",
    "\"Opisthorchis_felineus_GCA_004794785\",\n",
    "\"Opisthorchis_viverrini_GCA_001990785\",\n",
    "\"Schistosoma_bovis_GCA_003958945\",\n",
    "\"Schistosoma_curassoni_GCA_900618015\",\n",
    "\"Schistosoma_haematobium_GCA_000699445\",\n",
    "\"Schistosoma_japonicum_GCA_006368765\",\n",
    "\"Schistosoma_mattheei_GCA_900617995\",\n",
    "\"Schistostoma_margrebowiei_GCA_900618395\",\n",
    "\"Trichobilharzia_regenti_GCA_900618515\"]],\\\n",
    "                vmin=0, cmap=\"YlGnBu\",linewidths=.5,\\\n",
    "                annot=annotations, annot_kws={\"size\": 13}, fmt='g')\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.title(gene_class, fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
